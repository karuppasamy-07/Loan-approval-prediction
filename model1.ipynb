{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON Data\n",
    "file_path = 'D:\\loan pre\\loan_approval_dataset.json'\n",
    "\n",
    "# If the file is extremely large, consider using chunks\n",
    "chunks = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        chunks.append(json.loads(line))\n",
    "\n",
    "# Convert JSON to DataFrame\n",
    "data = pd.DataFrame(chunks)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON Data\n",
    "file_path = 'D:\\loan pre\\loan_approval_dataset.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Inspect the JSON structure\n",
    "print(type(data))  # Check the type of the loaded data\n",
    "print(data.keys())  # Print the keys of the top-level dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the JSON structure is a dictionary of dictionaries\n",
    "# Example structure:\n",
    "# {\n",
    "#     \"Car_Ownership\": {\"0\": \"no\", \"1\": \"no\", ...},\n",
    "#     \"Profession\": {\"0\": \"Mechanical_engineer\", \"1\": \"Software_Developer\", ...},\n",
    "#     ...\n",
    "# }\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each key in the top-level dictionary\n",
    "for key in data.keys():\n",
    "    # Convert each nested dictionary to a DataFrame and concatenate it to the main DataFrame\n",
    "    nested_df = pd.DataFrame.from_dict(data[key], orient='index', columns=[key])\n",
    "    df = pd.concat([df, nested_df], axis=1)\n",
    "\n",
    "# Reset index to have a proper DataFrame\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display basic information about the DataFrame\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values if necessary\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Ensure correct data types\n",
    "print(df.dtypes)\n",
    "\n",
    "# Convert data types if necessary\n",
    "# Example: df['column_name'] = df['column_name'].astype('desired_type')\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Distribution of Risk_Flag (Target Variable)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Risk_Flag', data=df)\n",
    "plt.title('Distribution of Risk_Flag')\n",
    "plt.xlabel('Risk_Flag')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of Age\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(x='Age', data=df, bins=30, kde=True)\n",
    "plt.title('Distribution of Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of Income\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(x='Income', data=df, bins=30, kde=True)\n",
    "plt.title('Distribution of Income')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between Age and Risk_Flag\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Risk_Flag', y='Age', data=df)\n",
    "plt.title('Relationship between Age and Risk_Flag')\n",
    "plt.xlabel('Risk_Flag')\n",
    "plt.ylabel('Age')\n",
    "plt.show()\n",
    "\n",
    "# Relationship between Income and Risk_Flag\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Risk_Flag', y='Income', data=df)\n",
    "plt.title('Relationship between Income and Risk_Flag')\n",
    "plt.xlabel('Risk_Flag')\n",
    "plt.ylabel('Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns for the correlation matrix\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns for the correlation matrix\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Create a subset of the DataFrame with numeric columns\n",
    "numeric_df = df[numeric_cols]\n",
    "\n",
    "# Plot the pairplot to visualize correlations and distributions\n",
    "sns.pairplot(numeric_df)\n",
    "plt.suptitle('Pairplot of Numeric Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Plot for Married/Single vs. Risk_Flag\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Married/Single', hue='Risk_Flag', data=df)\n",
    "plt.title('Married/Single vs. Risk_Flag')\n",
    "plt.xlabel('Married/Single')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Risk_Flag', loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Bar Plot for House_Ownership vs. Risk_Flag\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='House_Ownership', hue='Risk_Flag', data=df)\n",
    "plt.title('House_Ownership vs. Risk_Flag')\n",
    "plt.xlabel('House_Ownership')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Risk_Flag', loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Bar Plot for Car_Ownership vs. Risk_Flag\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Car_Ownership', hue='Risk_Flag', data=df)\n",
    "plt.title('Car_Ownership vs. Risk_Flag')\n",
    "plt.xlabel('Car_Ownership')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Risk_Flag', loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Bar Plot for Profession vs. Risk_Flag (displaying top professions)\n",
    "top_professions = df['Profession'].value_counts().nlargest(10).index\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Profession', hue='Risk_Flag', data=df[df['Profession'].isin(top_professions)])\n",
    "plt.title('Top Professions vs. Risk_Flag')\n",
    "plt.xlabel('Profession')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Risk_Flag', loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot for Age vs. Married/Single\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Married/Single', y='Age', data=df)\n",
    "plt.title('Age vs. Married/Single')\n",
    "plt.xlabel('Married/Single')\n",
    "plt.ylabel('Age')\n",
    "plt.show()\n",
    "\n",
    "# Box Plot for Income vs. House_Ownership\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='House_Ownership', y='Income', data=df)\n",
    "plt.title('Income vs. House_Ownership')\n",
    "plt.xlabel('House_Ownership')\n",
    "plt.ylabel('Income')\n",
    "plt.show()\n",
    "\n",
    "# Box Plot for Experience vs. Car_Ownership\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Car_Ownership', y='Experience', data=df)\n",
    "plt.title('Experience vs. Car_Ownership')\n",
    "plt.xlabel('Car_Ownership')\n",
    "plt.ylabel('Experience')\n",
    "plt.show()\n",
    "\n",
    "# Box Plot for Age vs. Profession (displaying top professions)\n",
    "top_professions = df['Profession'].value_counts().nlargest(10).index\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='Profession', y='Age', data=df[df['Profession'].isin(top_professions)])\n",
    "plt.title('Age vs. Profession (Top Professions)')\n",
    "plt.xlabel('Profession')\n",
    "plt.ylabel('Age')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sample DataFrame (replace this with your actual DataFrame)\n",
    "data = {\n",
    "    'Income': [1303834, 7574516, 3991815, 6256451, 5768871],\n",
    "    'Age': [23, 40, 66, 41, 47],\n",
    "    'Experience': [3, 10, 4, 2, 11],\n",
    "    'Married/Single': ['single', 'single', 'married', 'single', 'single'],\n",
    "    'House_Ownership': ['rented', 'rented', 'rented', 'rented', 'rented'],\n",
    "    'Car_Ownership': ['no', 'no', 'no', 'yes', 'no'],\n",
    "    'Profession': ['Mechanical_engineer', 'Software_Developer', 'Technical_writer', 'Software_Developer', 'Civil_servant'],\n",
    "    'CITY': ['Rewa', 'Parbhani', 'Alappuzha', 'Bhubaneswar', 'Tiruchirappalli[10]'],\n",
    "    'STATE': ['Madhya_Pradesh', 'Maharashtra', 'Kerala', 'Odisha', 'Tamil_Nadu'],\n",
    "    'CURRENT_JOB_YRS': [3, 9, 4, 2, 3],\n",
    "    'CURRENT_HOUSE_YRS': [13, 13, 10, 12, 14],\n",
    "    'Risk_Flag': [0, 0, 0, 1, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Scatter Plot for Income vs. Age (colored by Risk_Flag)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Income', y='Age', hue='Risk_Flag', data=df, palette='Set2')\n",
    "plt.title('Income vs. Age (Colored by Risk_Flag)')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Age')\n",
    "plt.legend(title='Risk_Flag')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dask-ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = 'D:\\loan pre\\loan_approval_dataset.json'\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.isfile(json_file_path):\n",
    "    print(\"JSON file exists.\")\n",
    "else:\n",
    "    print(\"JSON file does not exist or path is incorrect.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the absolute path to your JSON file\n",
    "absolute_json_path = 'D:\\loan pre\\loan_approval_dataset.json'\n",
    "\n",
    "# Load JSON data from the file\n",
    "with open(absolute_json_path, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Now 'data' contains the JSON data from your file, and you can work with it as needed\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named 'df'\n",
    "\n",
    "# Convert object columns to categorical if needed\n",
    "object_cols = df.select_dtypes(include=['object']).columns\n",
    "df[object_cols] = df[object_cols].astype('category')\n",
    "\n",
    "# Perform any additional preprocessing steps, such as encoding categorical variables, scaling numerical variables, etc.\n",
    "\n",
    "# For example, if you want to encode categorical variables using one-hot encoding:\n",
    "df_encoded = pd.get_dummies(df, columns=object_cols, drop_first=True)\n",
    "\n",
    "# Standardize numerical variables if needed\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = df.select_dtypes(include=['int64']).columns\n",
    "df_encoded[numerical_cols] = scaler.fit_transform(df_encoded[numerical_cols])\n",
    "\n",
    "# Now df_encoded contains your preprocessed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Columns to encode\n",
    "columns_to_encode = ['Married/Single', 'House_Ownership', 'Car_Ownership', 'Profession', 'CITY', 'STATE']\n",
    "\n",
    "# Perform one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=columns_to_encode)\n",
    "\n",
    "# Display the first few rows of the encoded DataFrame\n",
    "print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df_encoded is your encoded DataFrame\n",
    "# Splitting the data into features (X) and target variable (y)\n",
    "X = df_encoded.drop('Risk_Flag', axis=1)  # Features\n",
    "y = df_encoded['Risk_Flag']  # Target variable\n",
    "\n",
    "# Splitting the data into training and testing sets (70% training, 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df_encoded is your encoded DataFrame\n",
    "# Splitting the data into features (X) and target variable (y)\n",
    "X = df_encoded.drop('Risk_Flag', axis=1)  # Features\n",
    "y = df_encoded['Risk_Flag']  # Target variable\n",
    "\n",
    "# Splitting the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Your dictionary data\n",
    "data = {\n",
    "    'Id': {'0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6},\n",
    "    'Income': {'0': 1303834, '1': 7574516, '2': 3991815, '3': 6256451, '4': 5768871, '5': 2419865},\n",
    "    'Age': {'0': 23, '1': 40, '2': 66, '3': 41, '4': 47, '5': 48},\n",
    "    'Experience': {'0': 3, '1': 10, '2': 4, '3': 2, '4': 11, '5': 9},\n",
    "    'Married/Single': {'0': 'single', '1': 'single', '2': 'married', '3': 'single', '4': 'single', '5': 'married'},\n",
    "    'House_Ownership': {'0': 'rented', '1': 'rented', '2': 'rented', '3': 'rented', '4': 'rented', '5': 'owned'},\n",
    "    'Car_Ownership': {'0': 'no', '1': 'no', '2': 'no', '3': 'yes', '4': 'no', '5': 'yes'},\n",
    "    'Profession': {'0': 'Mechanical_engineer', '1': 'Software_Developer', '2': 'Technical_writer', '3': 'Software_Developer', '4': 'Civil_servant', '5': 'Economist'},\n",
    "    'CITY': {'0': 'Rewa', '1': 'Parbhani', '2': 'Alappuzha', '3': 'Bhubaneswar', '4': 'Tiruchirappalli[10]', '5': 'Pune'},\n",
    "    'STATE': {'0': 'Madhya_Pradesh', '1': 'Maharashtra', '2': 'Kerala', '3': 'Odisha', '4': 'Tamil_Nadu', '5': 'Maharashtra'},\n",
    "    'CURRENT_JOB_YRS': {'0': 3, '1': 9, '2': 4, '3': 2, '4': 3, '5': 8},\n",
    "    'CURRENT_HOUSE_YRS': {'0': 13, '1': 13, '2': 10, '3': 12, '4': 14, '5': 15},\n",
    "    'Risk_Flag': {'0': 0, '1': 0, '2': 0, '3': 1, '4': 1, '5': 0}\n",
    "}\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the number of data points\n",
    "print(\"Number of data points:\", df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'D:\\loan pre\\loan_approval_dataset.json'  # Update with actual path\n",
    "with open(file_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Number of data points:\", df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "X = df.drop('Risk_Flag', axis=1)\n",
    "y = df['Risk_Flag']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['bool']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocess the data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', 'passthrough', categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply the transformations to the training and test sets\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# Convert the transformed data back to a DataFrame for easier inspection\n",
    "X_train = pd.DataFrame(X_train, columns=numerical_cols + categorical_cols)\n",
    "X_test = pd.DataFrame(X_test, columns=numerical_cols + categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Classification report and confusion matrix\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Predict probabilities for ROC AUC\n",
    "y_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize the XGBoost Classifier\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Reduced parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV with fewer iterations\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid, n_iter=10, cv=3, scoring='recall', n_jobs=-1, verbose=2, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "# Fit the best model\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Classification report and confusion matrix\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Predict probabilities for ROC AUC\n",
    "y_prob = best_xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the model with class weight adjustments\n",
    "xgb_model = XGBClassifier(scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]))\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "y_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the model on resampled data\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate the model as before\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "y_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'scale_pos_weight': [1, len(y_train[y_train == 0]) / len(y_train[y_train == 1])]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='recall', cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "y_prob = best_xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "\n",
    "# Load your data (assuming X_train, X_test, y_train, y_test are already defined)\n",
    "\n",
    "# Step 1: Adjust Class Weights\n",
    "class_weight_ratio = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "model = XGBClassifier(scale_pos_weight=class_weight_ratio)\n",
    "\n",
    "# Train the model with class weights\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model with class weights\n",
    "y_pred = model.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)\n",
    "\n",
    "# Step 2: Apply SMOTE for Balancing\n",
    "smote = SMOTE()\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the model on the balanced data\n",
    "model.fit(X_smote, y_smote)\n",
    "\n",
    "# Evaluate the model with SMOTE\n",
    "y_pred = model.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)\n",
    "\n",
    "# Step 3: Hyperparameter Tuning\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV instead of GridSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Number of parameter settings that are sampled\n",
    "    scoring='recall',\n",
    "    cv=3,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model after hyperparameter tuning\n",
    "y_pred = best_model.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# Adjust the scale_pos_weight parameter\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# Initialize the model with class weights\n",
    "model = XGBClassifier(scale_pos_weight=scale_pos_weight, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Number of parameter settings that are sampled\n",
    "    scoring='recall',  # Focus on improving recall\n",
    "    cv=3,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model after hyperparameter tuning\n",
    "y_pred = best_model.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Get the probabilities for the positive class\n",
    "y_probs = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "# Find the optimal threshold\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Apply the optimal threshold\n",
    "y_pred_optimal = (y_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate the model with the optimal threshold\n",
    "evaluate_model(y_test, y_pred_optimal)\n",
    "\n",
    "print(f\"Optimal Threshold: {optimal_threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Predict probabilities\n",
    "y_probs = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Apply the optimal threshold\n",
    "optimal_threshold = 0.5866\n",
    "y_pred_optimal = (y_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate the model with the optimal threshold\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_optimal))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_optimal))\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n",
    "print(f\"Optimal Threshold: {optimal_threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install reportlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fpdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from fpdf import FPDF\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_json('loan_approval_dataset.json')\n",
    "\n",
    "# Data Exploration\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check class balance\n",
    "print(\"\\nClass Balance:\")\n",
    "print(df['Risk_Flag'].value_counts())\n",
    "\n",
    "# Visualize class distribution\n",
    "sns.countplot(x='Risk_Flag', data=df)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Feature Engineering\n",
    "# Split data into features and target\n",
    "X = df.drop('Risk_Flag', axis=1)\n",
    "y = df['Risk_Flag']\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['number']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define preprocessing steps for numerical and categorical data\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps for both types of data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply preprocessing to training data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "# Apply preprocessing to test data\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Model Building\n",
    "# Initialize and train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_preprocessed)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nROC AUC Score:\")\n",
    "roc_auc = roc_auc_score(y_test, rf_model.predict_proba(X_test_preprocessed)[:, 1])\n",
    "print(roc_auc)\n",
    "\n",
    "# Resampling for Class Imbalance\n",
    "# Upsample the minority class\n",
    "df_majority = df[df['Risk_Flag'] == 0]\n",
    "df_minority = df[df['Risk_Flag'] == 1]\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Perform train-test split again\n",
    "X_upsampled = df_upsampled.drop('Risk_Flag', axis=1)\n",
    "y_upsampled = df_upsampled['Risk_Flag']\n",
    "X_train_up, X_test_up, y_train_up, y_test_up = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply preprocessing to training data for upsampled data\n",
    "X_train_up_preprocessed = preprocessor.fit_transform(X_train_up)\n",
    "# Apply preprocessing to test data for upsampled data\n",
    "X_test_up_preprocessed = preprocessor.transform(X_test_up)\n",
    "\n",
    "# Train a new model on upsampled data\n",
    "rf_model_upsampled = RandomForestClassifier(random_state=42)\n",
    "rf_model_upsampled.fit(X_train_up_preprocessed, y_train_up)\n",
    "\n",
    "# Evaluate the upsampled model\n",
    "y_pred_up = rf_model_upsampled.predict(X_test_up_preprocessed)\n",
    "print(\"\\nUpsampled Classification Report:\")\n",
    "print(classification_report(y_test_up, y_pred_up))\n",
    "print(\"\\nUpsampled Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_up, y_pred_up))\n",
    "print(\"\\nUpsampled ROC AUC Score:\")\n",
    "roc_auc_up = roc_auc_score(y_test_up, rf_model_upsampled.predict_proba(X_test_up_preprocessed)[:, 1])\n",
    "print(roc_auc_up)\n",
    "\n",
    "# Generate PDF Report\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, 'Loan Approval Prediction Analysis Report', align='C', ln=True)\n",
    "        self.ln(10)\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, title, ln=True)\n",
    "        self.ln(5)\n",
    "\n",
    "    def chapter_body(self, body):\n",
    "        self.set_font('Arial', '', 12)\n",
    "        self.multi_cell(0, 10, body)\n",
    "        self.ln()\n",
    "\n",
    "    def add_plot(self, title, plot):\n",
    "        self.chapter_title(title)\n",
    "        self.image(plot, x=None, y=None, w=180)\n",
    "        self.ln()\n",
    "\n",
    "pdf = PDF()\n",
    "pdf.add_page()\n",
    "\n",
    "# Introduction\n",
    "pdf.chapter_title(\"Introduction\")\n",
    "pdf.chapter_body(\"This report presents the analysis of loan approval prediction using machine learning models.\")\n",
    "\n",
    "# Data Exploration\n",
    "pdf.chapter_title(\"Data Exploration\")\n",
    "pdf.chapter_body(\"The dataset contains information about loan applications, including various features like income, credit score, and loan amount.\")\n",
    "\n",
    "# Feature Engineering\n",
    "pdf.chapter_title(\"Feature Engineering\")\n",
    "pdf.chapter_body(\"Numerical features were scaled using StandardScaler for model training.\")\n",
    "\n",
    "# Model Building\n",
    "pdf.chapter_title(\"Model Building\")\n",
    "pdf.chapter_body(\"A Random Forest Classifier was trained on the dataset.\")\n",
    "\n",
    "# Evaluation Metrics\n",
    "pdf.chapter_title(\"Evaluation Metrics\")\n",
    "pdf.chapter_body(f\"ROC AUC Score: {roc_auc}\\n\\nClassification Report:\\n{classification_report(y_test, y_pred)}\\n\\nConfusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "\n",
    "# Recommendations\n",
    "pdf.chapter_title(\"Recommendations\")\n",
    "pdf.chapter_body(\"Upsampling the minority class improved model performance. Consider using resampling techniques for imbalanced datasets.\")\n",
    "\n",
    "# Save PDF Report\n",
    "pdf_file = \"loan_approval_analysis_report.pdf\"\n",
    "pdf.output(pdf_file)\n",
    "print(f\"\\nPDF Report generated successfully: {pdf_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a new model on upsampled data\n",
    "rf_model_upsampled = RandomForestClassifier(random_state=42)\n",
    "rf_model_upsampled.fit(X_train_up_preprocessed, y_train_up)\n",
    "\n",
    "# Evaluate the upsampled model\n",
    "y_pred_up = rf_model_upsampled.predict(X_test_up_preprocessed)\n",
    "print(\"\\nUpsampled Classification Report:\")\n",
    "print(classification_report(y_test_up, y_pred_up))\n",
    "print(\"\\nUpsampled Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_up, y_pred_up))\n",
    "print(\"\\nUpsampled ROC AUC Score:\")\n",
    "roc_auc_up = roc_auc_score(y_test_up, rf_model_upsampled.predict_proba(X_test_up_preprocessed)[:, 1])\n",
    "print(roc_auc_up)\n",
    "\n",
    "# Generate PDF Report\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, 'Loan Approval Prediction Analysis Report', align='C', ln=True)\n",
    "        self.ln(10)\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, title, ln=True)\n",
    "        self.ln(5)\n",
    "\n",
    "    def chapter_body(self, body):\n",
    "        self.set_font('Arial', '', 12)\n",
    "        self.multi_cell(0, 10, body)\n",
    "        self.ln()\n",
    "\n",
    "    def add_code(self, code):\n",
    "        self.set_font('Courier', '', 10)\n",
    "        self.multi_cell(0, 10, code)\n",
    "        self.ln()\n",
    "\n",
    "    def add_plot(self, title, plot):\n",
    "        self.chapter_title(title)\n",
    "        self.image(plot, x=None, y=None, w=180)\n",
    "        self.ln()\n",
    "\n",
    "pdf = PDF()\n",
    "pdf.add_page()\n",
    "\n",
    "# Introduction\n",
    "pdf.chapter_title(\"Introduction\")\n",
    "pdf.chapter_body(\"This report presents the analysis of loan approval prediction using machine learning models.\")\n",
    "\n",
    "# Data Exploration\n",
    "pdf.chapter_title(\"Data Exploration\")\n",
    "pdf.chapter_body(\"The dataset contains information about loan applications, including various features like income, credit score, and loan amount.\")\n",
    "pdf.add_plot(\"Class Distribution\", \"class_distribution.png\")\n",
    "\n",
    "# Feature Engineering\n",
    "pdf.chapter_title(\"Feature Engineering\")\n",
    "pdf.chapter_body(\"Numerical features were scaled using StandardScaler for model training.\")\n",
    "\n",
    "# Model Building\n",
    "pdf.chapter_title(\"Model Building\")\n",
    "pdf.chapter_body(\"A Random Forest Classifier was trained on the dataset.\")\n",
    "\n",
    "# Evaluation Metrics\n",
    "pdf.chapter_title(\"Evaluation Metrics\")\n",
    "pdf.chapter_body(f\"ROC AUC Score: {roc_auc}\\n\\nClassification Report:\\n{classification_report(y_test, y_pred)}\\n\\nConfusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "\n",
    "# Upsampled Model Evaluation Metrics\n",
    "pdf.chapter_title(\"Upsampled Model Evaluation Metrics\")\n",
    "pdf.chapter_body(f\"ROC AUC Score: {roc_auc_up}\\n\\nClassification Report:\\n{classification_report(y_test_up, y_pred_up)}\\n\\nConfusion Matrix:\\n{confusion_matrix(y_test_up, y_pred_up)}\")\n",
    "\n",
    "# Recommendations\n",
    "pdf.chapter_title(\"Recommendations\")\n",
    "pdf.chapter_body(\"Upsampling the minority class improved model performance. Consider using resampling techniques for imbalanced datasets.\")\n",
    "\n",
    "# Code Section\n",
    "pdf.chapter_title(\"Code Implementation\")\n",
    "code = \"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from fpdf import FPDF\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_json('loan_approval_dataset.json')\n",
    "\n",
    "# Data Exploration\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\\\nClass Balance:\")\n",
    "print(df['Risk_Flag'].value_counts())\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Risk_Flag', data=df)\n",
    "plt.title('Class Distribution')\n",
    "plt.savefig('class_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Feature Engineering\n",
    "X = df.drop('Risk_Flag', axis=1)\n",
    "y = df['Risk_Flag']\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['number']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define preprocessing steps for numerical and categorical data\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps for both types of data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Model Building\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_preprocessed)\n",
    "print(\"\\\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\\\nROC AUC Score:\")\n",
    "roc_auc = roc_auc_score(y_test, rf_model.predict_proba(X_test_preprocessed)[:, 1])\n",
    "print(roc_auc)\n",
    "\n",
    "# Resampling for Class Imbalance\n",
    "df_majority = df[df['Risk_Flag'] == 0]\n",
    "df_minority = df[df['Risk_Flag'] == 1]\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Perform train-test split again\n",
    "X_upsampled = df_upsampled.drop('Risk_Flag', axis=1)\n",
    "y_upsampled = df_upsampled['Risk_Flag']\n",
    "X_train_up, X_test_up, y_train_up, y_test_up = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply preprocessing to training data for upsampled data\n",
    "X_train_up_preprocessed = preprocessor.fit_transform(X_train_up)\n",
    "X_test_up_preprocessed = preprocessor.transform(X_test_up)\n",
    "\n",
    "# Train a new model on upsampled data\n",
    "rf_model_upsampled = RandomForestClassifier(random_state=42)\n",
    "rf_model_upsampled.fit(X_train_up_preprocessed, y_train_up)\n",
    "\n",
    "# Evaluate the upsampled model\n",
    "y_pred_up = rf_model_upsampled.predict(X_test_up_preprocessed)\n",
    "print(\"\\\\nUpsampled Classification Report:\")\n",
    "print(classification_report(y_test_up, y_pred_up))\n",
    "print(\"\\\\nUpsampled Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_up, y_pred_up))\n",
    "print(\"\\\\nUpsampled ROC AUC Score:\")\n",
    "roc_auc_up = roc_auc_score(y_test_up, rf_model_upsampled.predict_proba(X_test_up_preprocessed)[:, 1])\n",
    "print(roc_auc_up)\n",
    "\"\"\"\n",
    "pdf.add_code(code)\n",
    "\n",
    "# Save the PDF\n",
    "pdf.output('Loan_Approval_Prediction_Report.pdf')\n",
    "pdf.output(pdf_file)\n",
    "print(f\"\\nPDF Report generated successfully: {pdf_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from fpdf import FPDF\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_json('loan_approval_dataset.json')\n",
    "\n",
    "# Data Exploration\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nClass Balance:\")\n",
    "print(df['Risk_Flag'].value_counts())\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Risk_Flag', data=df)\n",
    "plt.title('Class Distribution')\n",
    "plt.savefig('class_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Feature Engineering\n",
    "X = df.drop('Risk_Flag', axis=1)\n",
    "y = df['Risk_Flag']\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['number']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define preprocessing steps for numerical and categorical data\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps for both types of data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Model Building\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_preprocessed)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nROC AUC Score:\")\n",
    "roc_auc = roc_auc_score(y_test, rf_model.predict_proba(X_test_preprocessed)[:, 1])\n",
    "print(roc_auc)\n",
    "\n",
    "# Resampling for Class Imbalance\n",
    "df_majority = df[df['Risk_Flag'] == 0]\n",
    "df_minority = df[df['Risk_Flag'] == 1]\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Perform train-test split again\n",
    "X_upsampled = df_upsampled.drop('Risk_Flag', axis=1)\n",
    "y_upsampled = df_upsampled['Risk_Flag']\n",
    "X_train_up, X_test_up, y_train_up, y_test_up = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
    "X_train_up_preprocessed = preprocessor.fit_transform(X_train_up)\n",
    "X_test_up_preprocessed = preprocessor.transform(X_test_up)\n",
    "\n",
    "# Train a new model on upsampled data\n",
    "rf_model_upsampled = RandomForestClassifier(random_state=42)\n",
    "rf_model_upsampled.fit(X_train_up_preprocessed, y_train_up)\n",
    "\n",
    "# Evaluate the upsampled model\n",
    "y_pred_up = rf_model_upsampled.predict(X_test_up_preprocessed)\n",
    "print(\"\\nUpsampled Classification Report:\")\n",
    "print(classification_report(y_test_up, y_pred_up))\n",
    "print(\"\\nUpsampled Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_up, y_pred_up))\n",
    "print(\"\\nUpsampled ROC AUC Score:\")\n",
    "roc_auc_up = roc_auc_score(y_test_up, rf_model_upsampled.predict_proba(X_test_up_preprocessed)[:, 1])\n",
    "print(roc_auc_up)\n",
    "\n",
    "# Generate PDF Report\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, 'Loan Approval Prediction Analysis Report', align='C', ln=True)\n",
    "        self.ln(10)\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, title, ln=True)\n",
    "        self.ln(5)\n",
    "\n",
    "    def chapter_body(self, body):\n",
    "        self.set_font('Arial', '', 12)\n",
    "        self.multi_cell(0, 10, body)\n",
    "        self.ln()\n",
    "\n",
    "    def add_code(self, code):\n",
    "        self.set_font('Courier', '', 10)\n",
    "        self.multi_cell(0, 10, code)\n",
    "        self.ln()\n",
    "\n",
    "    def add_plot(self, title, plot):\n",
    "        self.chapter_title(title)\n",
    "        self.image(plot, x=None, y=None, w=180)\n",
    "        self.ln()\n",
    "\n",
    "pdf = PDF()\n",
    "pdf.add_page()\n",
    "\n",
    "# Introduction\n",
    "pdf.chapter_title(\"Introduction\")\n",
    "pdf.chapter_body(\"This report presents the analysis of loan approval prediction using machine learning models.\")\n",
    "\n",
    "# Data Exploration\n",
    "pdf.chapter_title(\"Data Exploration\")\n",
    "pdf.chapter_body(\"The dataset contains information about loan applications, including various features like income, credit score, and loan amount.\")\n",
    "pdf.add_plot(\"Class Distribution\", \"class_distribution.png\")\n",
    "\n",
    "# Feature Engineering\n",
    "pdf.chapter_title(\"Feature Engineering\")\n",
    "pdf.chapter_body(\"Numerical features were scaled using StandardScaler for model training.\")\n",
    "\n",
    "# Model Building\n",
    "pdf.chapter_title(\"Model Building\")\n",
    "pdf.chapter_body(\"A Random Forest Classifier was trained on the dataset.\")\n",
    "\n",
    "# Evaluation Metrics\n",
    "pdf.chapter_title(\"Evaluation Metrics\")\n",
    "pdf.chapter_body(f\"ROC AUC Score: {roc_auc}\\n\\nClassification Report:\\n{classification_report(y_test, y_pred)}\\n\\nConfusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "\n",
    "# Recommendations\n",
    "pdf.chapter_title(\"Recommendations\")\n",
    "pdf.chapter_body(\"Upsampling the minority class improved model performance. Consider using resampling techniques for imbalanced datasets.\")\n",
    "\n",
    "# Code Section\n",
    "pdf.chapter_title(\"Code Implementation\")\n",
    "code = \"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from fpdf import FPDF\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_json('loan_approval_dataset.json')\n",
    "\n",
    "# Data Exploration\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\\\nClass Balance:\")\n",
    "print(df['Risk_Flag'].value_counts())\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Risk_Flag', data=df)\n",
    "plt.title('Class Distribution')\n",
    "plt.savefig('class_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Feature Engineering\n",
    "X = df.drop('Risk_Flag', axis=1)\n",
    "y = df['Risk_Flag']\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['number']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define preprocessing steps for numerical and categorical data\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps for both types of data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Model Building\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_preprocessed)\n",
    "print(\"\\\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\\\nROC AUC Score:\")\n",
    "roc_auc = roc_auc_score(y_test, rf_model.predict_proba(X_test_preprocessed)[:, 1])\n",
    "print(roc_auc)\n",
    "\n",
    "# Resampling for Class Imbalance\n",
    "df_majority = df[df['Risk_Flag'] == 0]\n",
    "df_minority = df[df['Risk_Flag'] == 1]\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Perform train-test split again\n",
    "X_upsampled = df_upsampled.drop('Risk_Flag', axis=1)\n",
    "y_upsampled = df_upsampled['Risk_Flag']\n",
    "X_train_up, X_test_up, y_train_up, y_test_up = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
    "X_train_up_preprocessed = preprocessor.fit_transform(X_train_up)\n",
    "X_test_up_preprocessed = preprocessor.transform(X_test_up)\n",
    "\n",
    "# Train a new model on upsampled data\n",
    "rf_model_upsampled = RandomForestClassifier(random_state=42)\n",
    "rf_model_upsampled.fit(X_train_up_preprocessed, y_train_up)\n",
    "\n",
    "# Evaluate the upsampled model\n",
    "y_pred_up = rf_model_upsampled.predict(X_test_up_preprocessed)\n",
    "print(\"\\\\nUpsampled Classification Report:\")\n",
    "print(classification_report(y_test_up, y_pred_up))\n",
    "print(\"\\\\nUpsampled Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_up, y_pred_up))\n",
    "print(\"\\\\nUpsampled ROC AUC Score:\")\n",
    "roc_auc_up = roc_auc_score(y_test_up, rf_model_upsampled.predict_proba(X_test_up_preprocessed)[:, 1])\n",
    "print(roc_auc_up)\n",
    "\"\"\"\n",
    "pdf.add_code(code)\n",
    "\n",
    "pdf.output(\"loan_approval_analysis_report_v2.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
